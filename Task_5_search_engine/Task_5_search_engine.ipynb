{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d1a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "inv_index = {}\n",
    "\n",
    "# считывание инвертированного индекса из файла\n",
    "\n",
    "with open('./db/inverted_index.txt', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        word = line[:line.index('{')-2]\n",
    "        rest = line[line.index('{')-1:]\n",
    "        inv_index[word] = json.loads(rest)\n",
    "\n",
    "tf_idf = {}\n",
    "        \n",
    "# считывание данных tf-idf из файла\n",
    "\n",
    "with open('./db/tf_idf.txt','r') as file:\n",
    "    tf_idf = json.loads(file.read())\n",
    "    \n",
    "# считывание ссылок документов из файла\n",
    "    \n",
    "path='./db/index.txt'\n",
    "docs = []\n",
    "with open(path,'r') as file:\n",
    "    text = ''\n",
    "    for line in file.readlines():\n",
    "        docs.append(line.split(' ')[-1].replace('\\n', ''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1cf7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "# получение номеров документов, в котором встречается данное слово\n",
    "\n",
    "def one_word_query(word, inv_index):\n",
    "    word = word.strip()\n",
    "    word = morph.normal_forms(word)[0]\n",
    "    res = []\n",
    "    if word in inv_index.keys():\n",
    "        res = inv_index[word].keys()\n",
    "    return res\n",
    "\n",
    "# получение номеров документов, в котором встречается каждое слово из данного запроса\n",
    "\n",
    "def phrase_query(query, inv_index):\n",
    "    ll = []\n",
    "    words = to_words(query)\n",
    "    for word in words:\n",
    "        if word in inv_index.keys():\n",
    "            ll.append(inv_index[word].keys())\n",
    "    setted = set(ll[0]).intersection(*ll)\n",
    "    return list(setted)\n",
    "\n",
    "def similarity(vec1, vec2):\n",
    "    return 1 - spatial.distance.cosine(vec1, vec2)\n",
    "\n",
    "def to_words(query):\n",
    "    words = query.split(' ')\n",
    "    for i in range(len(words)):\n",
    "        word = words[i].strip()\n",
    "        word = morph.normal_forms(word)[0]\n",
    "        words[i] = word\n",
    "    return words\n",
    "\n",
    "# подсчет вектора значений tf-idf для каждого термина в запросе\n",
    "\n",
    "def query_vec(query, inv_index, lms_res):\n",
    "    words = to_words(query)\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        ww = words[i]\n",
    "        if ww not in inv_index.keys():\n",
    "            words.remove(ww)\n",
    "        else:\n",
    "            words[i] = ww\n",
    "            i+=1\n",
    "    query_vec = [0]*len(words)\n",
    "    for i in range(len(words)):\n",
    "        query_vec[i] = query_tf(words[i], words)*idf(words[i],lms_res)\n",
    "        \n",
    "    return query_vec\n",
    "    \n",
    "def query_tf(word, words):\n",
    "    c = 0\n",
    "    for w in words:\n",
    "        if w == word:\n",
    "            c+=1\n",
    "    return c/len(words)\n",
    "\n",
    "def idf(word, lms_res):\n",
    "    for key in lms_res.keys():\n",
    "        if word in lms_res[key].keys():\n",
    "            return lms_res[key][word][1]\n",
    "\n",
    "# получение вектора значений tf-idf всех терминов запроса для каждого документа\n",
    "        \n",
    "def doc_vecs(lms_res, docs, words):\n",
    "    doc_vecs = {}\n",
    "    for i in docs:\n",
    "        doc_vecs[i] = []\n",
    "        for w in words:\n",
    "            if w in lms_res[i].keys():\n",
    "                doc_vecs[i].append(lms_res[i][w][1])\n",
    "            else:\n",
    "                doc_vecs[i].append(0)\n",
    "    return doc_vecs\n",
    "\n",
    "# функция поиска\n",
    "\n",
    "def search(query, inv_index, lms_res, docs):\n",
    "    res = set(phrase_query(query, inv_index))\n",
    "    words = to_words(query)\n",
    "    for word in words:\n",
    "        for i in one_word_query(word, inv_index):\n",
    "            res.add(i)\n",
    "    ds = doc_vecs(lms_res, res, words)\n",
    "    qc = query_vec(query, inv_index, lms_res)\n",
    "    smls = [[similarity(ds[i], qc),i] for i in ds.keys() ]\n",
    "    smls.sort(key=lambda x: x[0])\n",
    "    result = []\n",
    "    print(smls)\n",
    "    for i in range(len(smls)):\n",
    "        result.append(docs[int(smls[i][1])-1])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4335506b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [31/Mar/2022 21:16:58] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Mar/2022 21:17:01] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999999999999998, '74'], [1, '14'], [1, '1']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [31/Mar/2022 21:17:09] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.376695351651557, '23'], [0.376695351651557, '20'], [0.376695351651557, '49'], [0.376695351651557, '60'], [0.376695351651557, '68'], [0.376695351651557, '24'], [0.376695351651557, '34'], [0.376695351651557, '80'], [0.376695351651557, '69'], [0.376695351651557, '64'], [0.376695351651557, '21'], [0.376695351651557, '95'], [0.376695351651557, '81'], [0.376695351651557, '29'], [0.376695351651557, '46'], [0.376695351651557, '88'], [0.376695351651557, '30'], [0.376695351651557, '31'], [0.376695351651557, '86'], [0.376695351651557, '99'], [0.376695351651557, '36'], [0.376695351651557, '97'], [0.376695351651557, '38'], [0.376695351651557, '54'], [0.376695351651557, '25'], [0.8052799292743292, '8'], [0.9263372021268009, '50'], [0.9263372021268009, '85'], [0.9263372021268009, '82'], [0.9263372021268009, '40'], [0.9263372021268009, '93'], [0.9263372021268009, '9'], [0.926337202126801, '74'], [0.926337202126801, '75'], [0.926337202126801, '76'], [0.926337202126801, '90'], [0.926337202126801, '35'], [0.926337202126801, '44'], [0.926337202126801, '4'], [0.9263372021268012, '12'], [0.9263372021268012, '56'], [0.9263372021268012, '43'], [0.9263372021268012, '41'], [0.9263372021268012, '7'], [0.9559274498559407, '71'], [0.9559274498559407, '33']]\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\",\"POST\"])\n",
    "def home():\n",
    "    if request.method == \"GET\":\n",
    "        return render_template('index.html')\n",
    "    elif request.method == \"POST\":\n",
    "        query = request.form['search']\n",
    "        content = search(query, inv_index, tf_idf, docs)\n",
    "        return render_template('index.html', content=content)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e9134b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
